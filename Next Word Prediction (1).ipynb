{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498dcd09-9b21-491a-a76b-68ec5195b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49ea84e5-c388-4a8f-ab89-2fad5a4fce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "     The Project Gutenberg eBook of The Blue Castle, by Lucy Maud Montgomery\n",
      "0     This eBook is for the use of anyone anywhere i...                     \n",
      "1     most other parts of the world at no cost and w...                     \n",
      "2     whatsoever. You may copy it, give it away or r...                     \n",
      "3     of the Project Gutenberg License included with...                     \n",
      "4     www.gutenberg.org. If you are not located in t...                     \n",
      "...                                                 ...                     \n",
      "6694                        facility: www.gutenberg.org                     \n",
      "6695  This website includes information about Projec...                     \n",
      "6696  including how to make donations to the Project...                     \n",
      "6697  Archive Foundation, how to help produce our ne...                     \n",
      "6698  subscribe to our email newsletter to hear abou...                     \n",
      "\n",
      "[6699 rows x 1 columns]\n",
      "Text file successfully converted to CSV!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the text file into a DataFrame\n",
    "file= pd.read_csv('blue_castle.txt', delimiter='\\t')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "print(file)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "file.to_csv('blue_castle.txt', index=False)\n",
    "\n",
    "print(\"Text file successfully converted to CSV!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff77d69-54c0-4e74-a7cb-9ae673c8cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Project Gutenberg eBook of The Blue Castle, by Lucy Maud Montgomery\n",
      "0  This eBook is for the use of anyone anywhere i...                     \n",
      "1  most other parts of the world at no cost and w...                     \n",
      "2  whatsoever. You may copy it, give it away or r...                     \n",
      "3  of the Project Gutenberg License included with...                     \n",
      "4  www.gutenberg.org. If you are not located in t...                     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file= pd.read_csv('blue_castle.txt')\n",
    "\n",
    "# Display the first few rows\n",
    "print(file.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5679917-b2e1-4a3c-8b27-ba53dd5faa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The Project Gutenberg eBook of The Blue Castle, by Lucy Maud Montgomery\" This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions \"whatsoever. You may copy it, give it away or re-use it under the terms\" of the Project Gutenberg License included with this eBook or online at \"www.gutenberg.org. If you are not located in the United States, you\" will have to check the laws of the country where you are located befo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"blue_castle.txt\", \"r\", encoding = \"utf8\" )\n",
    "\n",
    "#store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "     lines.append(i)\n",
    "\n",
    "#Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "    data = '  '. join(lines)\n",
    "\n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    "\n",
    "#remove unnecessary spaces\n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "428922b6-c429-4f4e-ac08-8307335b35f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407834"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdfbb511-c691-409b-9090-690c841db4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 112, 97, 587, 4, 1, 94, 147, 58, 2383, 2384, 1818, 51, 587, 42]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "#saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl','wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0360b78b-7a5a-48f1-b5b0-3d81b6c522b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72052"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac27a10d-5d7c-4be5-96fe-883405467a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8413\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e978952-508a-49e5-9ca3-240df11a7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length if sequences are: 72049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,  112,   97,  587],\n",
       "       [ 112,   97,  587,    4],\n",
       "       [  97,  587,    4,    1],\n",
       "       [ 587,    4,    1,   94],\n",
       "       [   4,    1,   94,  147],\n",
       "       [   1,   94,  147,   58],\n",
       "       [  94,  147,   58, 2383],\n",
       "       [ 147,   58, 2383, 2384],\n",
       "       [  58, 2383, 2384, 1818],\n",
       "       [2383, 2384, 1818,   51]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range (3, len(sequence_data)):\n",
    "  words = sequence_data[i-3:i+1]\n",
    "  sequences.append(words)\n",
    "\n",
    "print(\"The Length if sequences are:\" , len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f54a8878-c29c-45d6-953f-de90a0a0bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "  X.append(i[0:3])\n",
    "  y.append(i[3])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "474b7062-886b-422b-93ac-d2b9b4fec798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [[   1  112   97]\n",
      " [ 112   97  587]\n",
      " [  97  587    4]\n",
      " [ 587    4    1]\n",
      " [   4    1   94]\n",
      " [   1   94  147]\n",
      " [  94  147   58]\n",
      " [ 147   58 2383]\n",
      " [  58 2383 2384]\n",
      " [2383 2384 1818]]\n",
      "Response: [ 587    4    1   94  147   58 2383 2384 1818   51]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\", X[:10])\n",
    "print(\"Response:\", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e72c070a-3b88-42fd-99b5-dbf4fce52e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f34459e3-0954-42fc-922f-c60308a9d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Ensure the same vocab_size and embedding dimension\n",
    "vocab_size = 8413\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10))  # Removed input_length as it's deprecated\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc6f6658-44a9-4b85-8241-d5b6225b07f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 7.0118\n",
      "Epoch 1: loss improved from inf to 6.76844, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 390ms/step - loss: 7.0116\n",
      "Epoch 2/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 6.2708\n",
      "Epoch 2: loss improved from 6.76844 to 6.20952, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 368ms/step - loss: 6.2707\n",
      "Epoch 3/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 5.8234\n",
      "Epoch 3: loss improved from 6.20952 to 5.79924, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 362ms/step - loss: 5.8234\n",
      "Epoch 4/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 5.4940\n",
      "Epoch 4: loss improved from 5.79924 to 5.49677, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 370ms/step - loss: 5.4940\n",
      "Epoch 5/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 5.2585\n",
      "Epoch 5: loss improved from 5.49677 to 5.25343, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 379ms/step - loss: 5.2585\n",
      "Epoch 6/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 5.0287\n",
      "Epoch 6: loss improved from 5.25343 to 5.03186, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 377ms/step - loss: 5.0287\n",
      "Epoch 7/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 4.8009\n",
      "Epoch 7: loss improved from 5.03186 to 4.80935, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 377ms/step - loss: 4.8009\n",
      "Epoch 8/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 4.5639\n",
      "Epoch 8: loss improved from 4.80935 to 4.57802, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 377ms/step - loss: 4.5639\n",
      "Epoch 9/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 4.3041\n",
      "Epoch 9: loss improved from 4.57802 to 4.33776, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 379ms/step - loss: 4.3041\n",
      "Epoch 10/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 4.0428\n",
      "Epoch 10: loss improved from 4.33776 to 4.08820, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 386ms/step - loss: 4.0428\n",
      "Epoch 11/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 3.8021\n",
      "Epoch 11: loss improved from 4.08820 to 3.84353, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 382ms/step - loss: 3.8021\n",
      "Epoch 12/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 3.5448\n",
      "Epoch 12: loss improved from 3.84353 to 3.60197, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 368ms/step - loss: 3.5449\n",
      "Epoch 13/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 3.3070\n",
      "Epoch 13: loss improved from 3.60197 to 3.37114, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 354ms/step - loss: 3.3070\n",
      "Epoch 14/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.0511\n",
      "Epoch 14: loss improved from 3.37114 to 3.15284, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1580s\u001b[0m 1s/step - loss: 3.0512\n",
      "Epoch 15/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 2.8497\n",
      "Epoch 15: loss improved from 3.15284 to 2.93720, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 368ms/step - loss: 2.8498\n",
      "Epoch 16/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 2.6599\n",
      "Epoch 16: loss improved from 2.93720 to 2.73524, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 354ms/step - loss: 2.6599\n",
      "Epoch 17/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - loss: 2.4607 \n",
      "Epoch 17: loss improved from 2.73524 to 2.54627, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1126s\u001b[0m 1s/step - loss: 2.4608\n",
      "Epoch 18/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 2.2657\n",
      "Epoch 18: loss improved from 2.54627 to 2.35754, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 382ms/step - loss: 2.2658\n",
      "Epoch 19/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 2.0821\n",
      "Epoch 19: loss improved from 2.35754 to 2.17931, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 379ms/step - loss: 2.0822\n",
      "Epoch 20/20\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 1.8938\n",
      "Epoch 20: loss improved from 2.17931 to 1.99711, saving model to next_word.keras\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 376ms/step - loss: 1.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d76d6d520>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"next_word.keras\",  # Updated to `.keras` extension\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=20, batch_size=64, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fba6cb09-5368-4290-a717-0ca2232f8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Load the model and tokenizer\n",
    "model = load_model('next_word.keras')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predict_word = \"\"\n",
    "\n",
    "  for key, value in tokenizer.word_index.items():\n",
    "    if value == preds:\n",
    "      predicted_word = key\n",
    "      break\n",
    "\n",
    "  print(predicted_word)\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38d546-36ba-469e-a358-b3833173b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line: The project gutenburg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'project', 'gutenburg']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
      "gutenberg\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line: he was quite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'was', 'quite']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
      "prepared\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line: she is beautiful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'is', 'beautiful']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "enough\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line: it may all come to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'come', 'to']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "cool\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line: hello everyone hope you are okayy doing good and fine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'and', 'fine']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "and\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line: blue castle is looking wonderful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'looking', 'wonderful']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "and\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "  text = input(\"Enter your line:\")\n",
    "\n",
    "  if text == \"0\":\n",
    "    print(\"Execution completed....\")\n",
    "    break\n",
    "  \n",
    "  else:\n",
    "    try:\n",
    "      text = text.split(\" \")\n",
    "      text = text[-3:]\n",
    "      print(text)\n",
    "\n",
    "      Predict_Next_Words(model, tokenizer, text)\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "       print(\"Error occured: \",e)\n",
    "       continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f935e-4900-4897-9d5b-e7e46253d42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
